{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import missingno as msn\n",
    "\n",
    "import scipy\n",
    "import scipy.stats as st\n",
    "import statsmodels as sm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from scipy.stats import skew, boxcox_normmax, norm\n",
    "from scipy.special import boxcox1p\n",
    "import matplotlib.gridspec as gridspec\n",
    "import datetime\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn import ensemble\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.captureWarnings(True)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer # default yeo-jhonson transformu uyguluyor\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "import optuna.integration.lightgbm as lgbm\n",
    "\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\",None)\n",
    "pd.set_option(\"display.max_columns\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(r\"D:\\Kaggle\\Titanic\\train.csv\")\n",
    "train_data.set_index(\"PassengerId\", inplace=True)\n",
    "test_data = pd.read_csv(r\"D:\\Kaggle\\Titanic\\test.csv\")\n",
    "test_data.set_index(\"PassengerId\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols = train_data[[\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Pclass\"]]\n",
    "\n",
    "nominal_cols=train_data[[\"Ticket\",\"Embarked\"]]\n",
    "\n",
    "binary_cols=train_data[[\"Sex\"]]\n",
    "target_col=train_data[[\"Survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((train_data.loc[:,'Pclass':'Embarked'], test_data.loc[:,'Pclass':'Embarked']))\n",
    "\n",
    "df.drop(columns=[\"Age\",\"Cabin\",\"Name\",\"Ticket\"],axis=1,inplace=True)\n",
    "df.Embarked.fillna(\"S\",inplace=True)\n",
    "df.Fare.fillna(test_data.Fare.mean(), inplace=True)\n",
    "\n",
    "#train_data.drop(columns=[\"Age\",\"Cabin\",\"Name\",\"Ticket\"],axis=1,inplace=True)\n",
    "#test_data.drop(columns=[\"Age\",\"Cabin\",\"Name\",\"Ticket\"],axis=1,inplace=True)\n",
    "#\n",
    "#train_data.Embarked.fillna(\"S\",inplace=True)\n",
    "#test_data.Fare.fillna(test_data.Fare.mean(), inplace=True)\n",
    "\n",
    "map_sex = {\"male\":1, \"female\":0}\n",
    "map_embarked = {\"S\":0,\"C\":1,\"Q\":2}\n",
    "\n",
    "df.loc[:, \"Embarked\"] = df.Embarked.map(map_embarked)\n",
    "df.loc[:, \"Sex\"] = df.Sex.map(map_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=df.loc[:target_col.shape[0],:]\n",
    "test_data=df.loc[target_col.shape[0]+1:,:]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, target_col, test_size= 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'learning_rate': 0.5,\n",
       " 'max_depth': 5,\n",
       " 'n_estimators': 40}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier().fit(X_train, y_train)\n",
    "#Model Tuning\n",
    "lgbm_params = {\"colsample_bytree\":[0.4,0.5,1],\"learning_rate\":[0.01,0.1,0.5], \"max_depth\": [5,10,50,100], \"n_estimators\": [40,100,200,1000]}\n",
    "lgbm_cv = GridSearchCV(lgbm, lgbm_params, cv=5, n_jobs=-1, verbose=2)\n",
    "lgbm_cv.fit(X_valid, y_valid)\n",
    "lgbm_cv.best_params_ #{'colsample_bytree': 0.4, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final model\n",
    "lgbm_tuned = LGBMClassifier(learning_rate=0.5, max_depth=5, n_estimators=40, colsample_bytree=0.5)\n",
    "lgbm_tuned.fit(X_train, y_train)\n",
    "y_test_pred = lgbm_tuned.predict(X_valid)\n",
    "score = round(accuracy_score(y_valid, y_test_pred), 3)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lgbm_tuned, open(\"lightgbm_titanic_model.pkl\", \"wb\"))\n",
    "pickled_lgbm_titanic = pickle.load(open(\"lightgbm_titanic_model.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickled_lgbm_titanic.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
